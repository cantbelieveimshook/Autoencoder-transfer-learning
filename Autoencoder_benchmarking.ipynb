{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder benchmarking",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cantbelieveimshook/Autoencoder-transfer-learning/blob/main/Autoencoder_benchmarking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connects colab to your google drive\n",
        "# skip if your dataset is not on google drive or you're not using colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BQBJzYlE-og",
        "outputId": "97e7281c-ad60-4801-b6f1-08ba1a5dc7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import keras\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, BatchNormalization, Conv2DTranspose\n",
        "from tensorflow.keras.utils import  plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import h5py\n",
        "import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "from scipy.stats import norm\n",
        "from keras.constraints import UnitNorm, Constraint"
      ],
      "metadata": {
        "id": "KxCm0fhUDF7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filepath = '/content/drive/MyDrive/Big Data REU 2022 Team 1/REU 2022 Research/Datasets/newly_organized_pngs/'\n",
        "filepath = '/content/drive/MyDrive/Big Data REU 2022 Team 1/REU 2022 Research/Datasets/new-test-data_Seraj/fft-denoised/'\n",
        "os.chdir(filepath) # changes the current working directory to the file path specified. This directory should be the directory of data you plan on using for the model"
      ],
      "metadata": {
        "id": "37iflCX3E1st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # set batch_size to 32 because it seems to provide the best results given our dataset\n",
        "\n",
        "# this ImageDataGenerator is used for training, validation, and testing generators. No preprocessing besides dividing all values by 255 is carried out\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255\n",
        "        )\n",
        "\n",
        "train = train_datagen.flow_from_directory(\n",
        "        filepath + \"train/\",\n",
        "        target_size=(256, 256), # images, regardless of their original size, are shrunk down to 256 x 256 x 3\n",
        "        batch_size=batch_size,\n",
        "        color_mode = 'rgb',\n",
        "        class_mode='binary', # for binary classification\n",
        "        shuffle=False # do not shuffle images\n",
        "    )\n",
        "\n",
        "val = train_datagen.flow_from_directory(\n",
        "        filepath + \"validation/\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=batch_size,\n",
        "        color_mode = 'rgb',\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "test = train_datagen.flow_from_directory(\n",
        "        filepath + \"test/\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=batch_size,\n",
        "        color_mode = 'rgb',\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPXXK1EAIGEe",
        "outputId": "6cf58f66-cacf-4608-eaf6-a402c3804b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 710 images belonging to 2 classes.\n",
            "Found 140 images belonging to 2 classes.\n",
            "Found 236 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOYBBkYuDCeT"
      },
      "outputs": [],
      "source": [
        "# this model has the exact same architecture and regularizers as the classification model, but without any pre-trained weights\n",
        "# if images are not rgb, input_shape should be changed to (256, 256, 1) instead of (256, 256, 3)\n",
        "baseline = models.Sequential()\n",
        "baseline.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape = (256, 256, 3), kernel_regularizer = keras.regularizers.l2(l = 0.01)))\n",
        "baseline.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
        "baseline.add(layers.Conv2D(8, (3, 3), activation='relu', padding='same', kernel_regularizer = keras.regularizers.l2(l = 0.01)))\n",
        "baseline.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
        "baseline.add(layers.Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "baseline.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
        "baseline.add(keras.layers.Flatten())\n",
        "baseline.add(keras.layers.Dense(64, activation='relu'))\n",
        "baseline.add(keras.layers.Dropout(0.3))\n",
        "baseline.add(keras.layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline.compile(\n",
        "        optimizer='Adam',\n",
        "        metrics=['accuracy'],\n",
        "        loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "af92OTv8EyXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "h = baseline.fit(\n",
        "    train,\n",
        "    epochs=epochs,\n",
        "    validation_data=val,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtZOd1owFR56",
        "outputId": "e5480a12-4245-402f-b05e-a41b853b44ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 345s 14s/step - loss: 0.8639 - accuracy: 0.4324 - val_loss: 0.8346 - val_accuracy: 0.4929\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 17s 739ms/step - loss: 0.8258 - accuracy: 0.4930 - val_loss: 0.8167 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 19s 821ms/step - loss: 0.8095 - accuracy: 0.5000 - val_loss: 0.8021 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 17s 737ms/step - loss: 0.7965 - accuracy: 0.5000 - val_loss: 0.7905 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 17s 732ms/step - loss: 0.7861 - accuracy: 0.5000 - val_loss: 0.7813 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 17s 760ms/step - loss: 0.7779 - accuracy: 0.5000 - val_loss: 0.7739 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 17s 727ms/step - loss: 0.7711 - accuracy: 0.5000 - val_loss: 0.7677 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 17s 748ms/step - loss: 0.7654 - accuracy: 0.5000 - val_loss: 0.7625 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 17s 763ms/step - loss: 0.7605 - accuracy: 0.5000 - val_loss: 0.7581 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 18s 807ms/step - loss: 0.7562 - accuracy: 0.5000 - val_loss: 0.7541 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 17s 758ms/step - loss: 0.7524 - accuracy: 0.5000 - val_loss: 0.7505 - val_accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 17s 751ms/step - loss: 0.7493 - accuracy: 0.5000 - val_loss: 0.7472 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 17s 758ms/step - loss: 0.7458 - accuracy: 0.5000 - val_loss: 0.7442 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 17s 724ms/step - loss: 0.7430 - accuracy: 0.5000 - val_loss: 0.7414 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 17s 757ms/step - loss: 0.7405 - accuracy: 0.5000 - val_loss: 0.7387 - val_accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 17s 757ms/step - loss: 0.7377 - accuracy: 0.5000 - val_loss: 0.7363 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 18s 773ms/step - loss: 0.7353 - accuracy: 0.5000 - val_loss: 0.7339 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.7329 - accuracy: 0.5000 - val_loss: 0.7317 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 17s 725ms/step - loss: 0.7311 - accuracy: 0.5000 - val_loss: 0.7296 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 17s 725ms/step - loss: 0.7289 - accuracy: 0.5000 - val_loss: 0.7276 - val_accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 17s 730ms/step - loss: 0.7269 - accuracy: 0.5000 - val_loss: 0.7258 - val_accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 17s 749ms/step - loss: 0.7249 - accuracy: 0.5000 - val_loss: 0.7240 - val_accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 17s 742ms/step - loss: 0.7237 - accuracy: 0.4761 - val_loss: 0.7223 - val_accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 18s 799ms/step - loss: 0.7218 - accuracy: 0.5000 - val_loss: 0.7208 - val_accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 17s 730ms/step - loss: 0.7205 - accuracy: 0.5000 - val_loss: 0.7193 - val_accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 17s 734ms/step - loss: 0.7188 - accuracy: 0.5000 - val_loss: 0.7178 - val_accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 16s 738ms/step - loss: 0.7173 - accuracy: 0.5000 - val_loss: 0.7165 - val_accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 17s 707ms/step - loss: 0.7159 - accuracy: 0.5000 - val_loss: 0.7152 - val_accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 16s 701ms/step - loss: 0.7146 - accuracy: 0.5000 - val_loss: 0.7139 - val_accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 16s 704ms/step - loss: 0.7134 - accuracy: 0.5000 - val_loss: 0.7128 - val_accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 17s 752ms/step - loss: 0.7125 - accuracy: 0.5000 - val_loss: 0.7116 - val_accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 17s 708ms/step - loss: 0.7112 - accuracy: 0.5000 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 16s 701ms/step - loss: 0.7116 - accuracy: 0.5000 - val_loss: 0.7096 - val_accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 17s 732ms/step - loss: 0.7098 - accuracy: 0.5000 - val_loss: 0.7092 - val_accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 17s 706ms/step - loss: 0.7095 - accuracy: 0.5000 - val_loss: 0.7081 - val_accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 16s 704ms/step - loss: 0.7080 - accuracy: 0.5000 - val_loss: 0.7073 - val_accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 16s 702ms/step - loss: 0.7073 - accuracy: 0.5000 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 17s 784ms/step - loss: 0.7063 - accuracy: 0.5000 - val_loss: 0.7058 - val_accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 16s 728ms/step - loss: 0.7055 - accuracy: 0.5000 - val_loss: 0.7050 - val_accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 17s 735ms/step - loss: 0.7048 - accuracy: 0.5000 - val_loss: 0.7043 - val_accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 16s 732ms/step - loss: 0.7041 - accuracy: 0.5000 - val_loss: 0.7036 - val_accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 16s 724ms/step - loss: 0.7033 - accuracy: 0.5000 - val_loss: 0.7030 - val_accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 16s 735ms/step - loss: 0.7029 - accuracy: 0.5000 - val_loss: 0.7025 - val_accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 16s 734ms/step - loss: 0.7022 - accuracy: 0.5000 - val_loss: 0.7019 - val_accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 17s 732ms/step - loss: 0.7017 - accuracy: 0.5000 - val_loss: 0.7014 - val_accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 17s 783ms/step - loss: 0.7012 - accuracy: 0.5000 - val_loss: 0.7009 - val_accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 16s 735ms/step - loss: 0.7008 - accuracy: 0.5000 - val_loss: 0.7004 - val_accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 16s 735ms/step - loss: 0.7003 - accuracy: 0.5000 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 16s 701ms/step - loss: 0.7001 - accuracy: 0.5000 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 16s 731ms/step - loss: 0.6997 - accuracy: 0.5000 - val_loss: 0.6992 - val_accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 16s 733ms/step - loss: 0.6993 - accuracy: 0.5000 - val_loss: 0.6988 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 16s 701ms/step - loss: 0.6987 - accuracy: 0.5000 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 17s 784ms/step - loss: 0.6985 - accuracy: 0.5000 - val_loss: 0.6982 - val_accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 16s 739ms/step - loss: 0.6981 - accuracy: 0.5000 - val_loss: 0.6979 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 16s 701ms/step - loss: 0.6978 - accuracy: 0.5000 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 16s 703ms/step - loss: 0.6977 - accuracy: 0.5000 - val_loss: 0.6973 - val_accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 16s 701ms/step - loss: 0.6972 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 16s 704ms/step - loss: 0.6971 - accuracy: 0.5000 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 17s 711ms/step - loss: 0.6969 - accuracy: 0.5000 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 18s 793ms/step - loss: 0.6968 - accuracy: 0.5000 - val_loss: 0.6964 - val_accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 17s 740ms/step - loss: 0.6965 - accuracy: 0.5000 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 17s 708ms/step - loss: 0.6963 - accuracy: 0.5000 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 17s 717ms/step - loss: 0.6962 - accuracy: 0.5000 - val_loss: 0.6959 - val_accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 17s 745ms/step - loss: 0.6960 - accuracy: 0.5000 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 17s 738ms/step - loss: 0.6958 - accuracy: 0.5000 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 17s 709ms/step - loss: 0.6956 - accuracy: 0.5000 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 18s 757ms/step - loss: 0.6954 - accuracy: 0.5000 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 17s 745ms/step - loss: 0.6953 - accuracy: 0.5000 - val_loss: 0.6952 - val_accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 17s 744ms/step - loss: 0.6952 - accuracy: 0.5000 - val_loss: 0.6951 - val_accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 17s 744ms/step - loss: 0.6951 - accuracy: 0.5000 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 17s 747ms/step - loss: 0.6950 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 17s 713ms/step - loss: 0.6950 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 17s 712ms/step - loss: 0.6948 - accuracy: 0.5000 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 18s 759ms/step - loss: 0.6947 - accuracy: 0.5000 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 17s 717ms/step - loss: 0.6946 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 17s 748ms/step - loss: 0.6948 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 17s 749ms/step - loss: 0.6946 - accuracy: 0.5000 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 17s 755ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 17s 719ms/step - loss: 0.6943 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 17s 749ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 18s 795ms/step - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 17s 714ms/step - loss: 0.6945 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 17s 740ms/step - loss: 0.6943 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 17s 714ms/step - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 17s 716ms/step - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 17s 718ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 18s 795ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 17s 747ms/step - loss: 0.6943 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 17s 753ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 17s 722ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 17s 773ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 17s 757ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 17s 750ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 18s 770ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 17s 723ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 17s 725ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 17s 716ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 17s 718ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 17s 717ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average training accuracy: \",sum(h.history['accuracy'])/100)\n",
        "print(\"Average training loss: \",sum(h.history['loss'])/100)\n",
        "print(\"Average validation accuracy: \",sum(h.history['val_accuracy'])/100)\n",
        "print(\"Average validation loss: \",sum(h.history['val_loss'])/100)"
      ],
      "metadata": {
        "id": "t54Ncqhf7mzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01589257-70e1-4c13-d889-2347ec0dfb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training accuracy:  0.4993999996781349\n",
            "Average training loss:  1.6892051362991334\n",
            "Average validation accuracy:  0.4993333330750465\n",
            "Average validation loss:  0.8969045370817185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['accuracy'])\n",
        "plt.plot(h.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jjCKVWe0Aaq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SAZvOZK67-g"
      },
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = baseline.evaluate(test, verbose = 0)\n",
        "print('> %.3f' % (acc * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUl3tjr9Z8Sf",
        "outputId": "ae31eb6a-4839-45c8-c707-34ca13c7e151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 50.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "pred = baseline.predict(val)\n",
        "\n",
        "print(\"Confusion Matrix: \\n\")\n",
        "true_classes = val.classes\n",
        "class_labels = list(val.class_indices.keys())\n",
        "pred = np.round(pred)\n",
        "confusion_matrix = metrics.confusion_matrix(y_true=true_classes, y_pred=pred)\n",
        "confusion_matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUhTlnvWnQpO",
        "outputId": "fd6c692a-aecf-4a7e-a879-4fe3e181723a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 30],\n",
              "       [ 0, 30]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}